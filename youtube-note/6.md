# ML lec 6-1 - Softmax Regression: 기본 개념 소개

- logistic classfication(w)를 학습시킨다 : 두개를 구분하는 선을 찾는거다 ->hyperplane
- multinomial classification
  - 학점을 a,b,c 등으로 분류하는 선을 찾는것
  - a or not, b or not, c or not 으로 학습시키면 가능하다..
  - [[w1, w2, w3],[...], ...] * [[x1],[x2],[x3]] 으로 표현하자
  - 다 더하면 1이되게 하는 놈 : softmax
  - score to probability function
    - y -> [0.7, 0.2, 0.1] : 이런식으로 됨
    - 제일큰거 1로, 나머지는 0으로: one hot encoding
    - 이걸 통해서 분류기가 된다
##  코스트 함수 설계
- 크로스 엔트로피 사용
- y^
  

## question
- logit이 뭐지?
- sigmoid, softmax 간 관계?
- cross entropy 에서 gradient descent 사용한다는건 convex 하다는건가??

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "severe-holder",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.1173695\n",
      "20 1.1131747\n",
      "30 1.1092042\n",
      "40 1.1052849\n",
      "50 1.1014982\n",
      "60 1.097874\n",
      "70 1.0964313\n",
      "80 1.0951158\n",
      "90 1.0938008\n",
      "100 1.092506\n",
      "110 1.0912308\n",
      "120 1.0899748\n",
      "130 1.0887376\n",
      "140 1.0875187\n",
      "150 1.0862944\n",
      "160 1.0850811\n",
      "170 1.0838892\n",
      "180 1.0827408\n",
      "190 1.0816087\n",
      "200 1.0804925\n",
      "210 1.0793718\n",
      "220 1.078231\n",
      "230 1.0771617\n",
      "240 1.0761073\n",
      "250 1.0750216\n",
      "260 1.0739671\n",
      "270 1.0729555\n",
      "280 1.0722547\n",
      "290 1.0717468\n",
      "300 1.0712605\n",
      "예측값: [0 1 1 0 0 0]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 66.66667175292969\n"
     ]
    }
   ],
   "source": [
    "# 단층 신경망 구성\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_resource_variables()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 학습용 데이터 구성, [털, 날개]\n",
    "x_data = np.array([[0,0],\n",
    "                  [1,0],\n",
    "                  [1,1],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "# 레이블 데이터 구성\n",
    "# 원핫인코딩으로 작성\n",
    "# 기타=[1,0,0], 포유류=[0,1,0], 조류=[0,0,1]\n",
    "y_data = np.array([\n",
    "    [1,0,0], #기타\n",
    "    [0,1,0], #포유류\n",
    "    [0,0,1], #조류\n",
    "    [1,0,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "# 신경망 모델 구성\n",
    "X=tf.placeholder(tf.float32)\n",
    "Y=tf.placeholder(tf.float32)\n",
    "# 입출력 결과의 차원수만 잘 나타내주면 되는듯 하다.\n",
    "W = tf.Variable(tf.random_uniform([2,3], -1., 1.))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "L=tf.add(tf.matmul(X,W),b)\n",
    "L=tf.nn.relu(L)\n",
    "\n",
    "# 결과값의 전체합이 1이 되도록 만들어줌\n",
    "model = tf.nn.softmax(L)\n",
    "\n",
    "# 원핫인코딩->교차엔트로피 사용\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
    "\n",
    "## 학습\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 텐서플로 세션 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 앞서 구성한 특징과 레이블 데이터를 이용해 학습을 100번 진행\n",
    "for step in range(300):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    # 학습도중 10번에 1번씩 손실값 출력\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "# 예측값인 model을 바로 출력하면 [0.2 0.7 0.1]과 같은 확률로 나와\n",
    "# 요소중 가장 큰값의 인덱스를 찾아주는 argmax 사용\n",
    "# argmax : 결과중 가장 큰 인덱스를 찾아줌\n",
    "# 예시 : [[0 1 0] [1 0 0]]-> [1 0]\n",
    "#        [[0.2 0.7 0.1] [0.9 0.1 0.]]-> [1 0]\n",
    "prediction = tf.argmax(model, axis=1)\n",
    "target = tf.argmax(Y, axis=1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "# 정확도 출력\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: {}'.format(sess.run(accuracy*100, feed_dict={X:x_data, Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "running-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.8981491\n",
      "20 0.721123\n",
      "30 0.5974434\n",
      "40 0.49540982\n",
      "50 0.41119847\n",
      "60 0.34063277\n",
      "70 0.28362662\n",
      "80 0.23856997\n",
      "90 0.20303933\n",
      "100 0.17486246\n",
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 100.0\n"
     ]
    }
   ],
   "source": [
    "# 심층 신경망 구성\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_resource_variables()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 학습용 데이터 구성, [털, 날개]\n",
    "x_data = np.array([[0,0],\n",
    "                  [1,0],\n",
    "                  [1,1],\n",
    "                  [0,0],\n",
    "                  [0,0],\n",
    "                  [0,1]])\n",
    "# 레이블 데이터 구성\n",
    "# 원핫인코딩으로 작성\n",
    "# 기타=[1,0,0], 포유류=[0,1,0], 조류=[0,0,1]\n",
    "y_data = np.array([\n",
    "    [1,0,0], #기타\n",
    "    [0,1,0], #포유류\n",
    "    [0,0,1], #조류\n",
    "    [1,0,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "# 신경망 모델 구성\n",
    "X=tf.placeholder(tf.float32)\n",
    "Y=tf.placeholder(tf.float32)\n",
    "\n",
    "# w1=[2 10] -> [피쳐, 은닉층 뉴런수]\n",
    "# w2=[10 3] -> [은닉층 뉴런 수, 분류 수]\n",
    "W1 = tf.Variable(tf.random_uniform([2,10], -1., 1.))\n",
    "W2 = tf.Variable(tf.random_uniform([10,3], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "# 첫번째 가중치, 편향, 활성화 함수 적용\n",
    "L1=tf.add(tf.matmul(X,W1),b1)\n",
    "L1=tf.nn.relu(L1)\n",
    "# 출럭층을 만들기 위해 두번째 가중치와 편향을 적용\n",
    "# 출력층에서 활성화 함수 사용 x\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "# tensorflow가 기본 제공하는 교차 엔트로피 함수 이용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "## 학습\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 텐서플로 세션 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 앞서 구성한 특징과 레이블 데이터를 이용해 학습을 100번 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    # 학습도중 10번에 1번씩 손실값 출력\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "# 예측값인 model을 바로 출력하면 [0.2 0.7 0.1]과 같은 확률로 나와\n",
    "# 요소중 가장 큰값의 인덱스를 찾아주는 argmax 사용\n",
    "# argmax : 결과중 가장 큰 인덱스를 찾아줌\n",
    "# 예시 : [[0 1 0] [1 0 0]]-> [1 0]\n",
    "#        [[0.2 0.7 0.1] [0.9 0.1 0.]]-> [1 0]\n",
    "prediction = tf.argmax(model, axis=1)\n",
    "target = tf.argmax(Y, axis=1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "# 정확도 출력\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: {}'.format(sess.run(accuracy*100, feed_dict={X:x_data, Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-reform",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
